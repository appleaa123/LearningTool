# Backend/ODR environment configuration

# Use keys passed in via LangGraph request config when true
GET_API_KEYS_FROM_CONFIG=true

# OpenAI or OpenRouter (OpenAI-compatible)
OPENAI_API_KEY= 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
# To use OpenRouter with openai:* models
OPENAI_BASE_URL=https://openrouter.ai/api/v1

# Anthropic
ANTHROPIC_API_KEY=

# Google / Gemini (GOOGLE_API_KEY is accepted for Gemini)
GOOGLE_API_KEY= AIzaSyCr_798sqi7LWy_uQcfl8sv4mk9p1bgJKI
GEMINI_API_KEY=AIzaSyCr_798sqi7LWy_uQcfl8sv4mk9p1bgJKI
GEMINI_DEFAULT_MODEL=gemini-1.5-flash
GEMINI_VISION_MODEL=gemini-1.5-flash
GEMINI_ASR_MODEL=gemini-1.5-flash

# Tavily search (recommended)
TAVILY_API_KEY=

# Optional other providers
GROQ_API_KEY=
DEEPSEEK_API_KEY=

# Optional: LangSmith/Tracing
LANGCHAIN_TRACING_V2=false
LANGCHAIN_API_KEY=
LANGCHAIN_PROJECT=deep-research


# Ingestion defaults and behavior
UPLOAD_TMP_DIR=/tmp
LIGHTRAG_BASE_DIR=/data/lightrag
SQLITE_DB_PATH=/data/app.db
INGEST_IMAGE_PROCESSOR=ocr        # ocr | gemini
INGEST_AUDIO_ASR=whisper          # whisper | openai | gemini
INGESTION_REDACT_PII=false        # true to enable regex-based redaction

# Whisper / ASR configuration
WHISPER_TMP=/tmp
WHISPER_LANG=en
WHISPER_MODEL=large-v3
FASTER_WHISPER_MODEL=medium
FASTER_WHISPER_DEVICE=cpu
FASTER_WHISPER_COMPUTE=int8

# Transformation model (for summarize/QA/flashcards)
TRANSFORM_MODEL_PROVIDER=gemini
TRANSFORM_MODEL=gemini-1.5-flash


