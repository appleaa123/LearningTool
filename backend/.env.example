# Backend/ODR environment configuration template
# Copy this file to 'env' (or '.env') and fill in your actual API keys

# Use keys passed in via LangGraph request config when true
GET_API_KEYS_FROM_CONFIG=true

# Image processing: use Gemini Vision API instead of tesseract OCR
INGEST_IMAGE_PROCESSOR=gemini

# OpenAI or OpenRouter (OpenAI-compatible)
OPENAI_API_KEY=sk-your-openai-api-key-here
# To use OpenRouter with openai:* models
OPENAI_BASE_URL=https://openrouter.ai/api/v1

# Anthropic
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# Google / Gemini (GOOGLE_API_KEY is accepted for Gemini)
GOOGLE_API_KEY=your-google-api-key-here
GEMINI_API_KEY=your-gemini-api-key-here
GEMINI_DEFAULT_MODEL=gemini-2.5-flash-lite
GEMINI_VISION_MODEL=gemini-2.5-flash-lite
GEMINI_ASR_MODEL=gemini-2.5-flash-lite

# Tavily search (recommended)
TAVILY_API_KEY=tvly-your-tavily-api-key-here

# Optional other providers
GROQ_API_KEY=your-groq-api-key-here
DEEPSEEK_API_KEY=your-deepseek-api-key-here

# Optional: LangSmith/Tracing
LANGCHAIN_TRACING_V2=false
LANGCHAIN_API_KEY=your-langchain-api-key-here
LANGCHAIN_PROJECT=deep-research


# Ingestion defaults and behavior
UPLOAD_TMP_DIR=/tmp
LIGHTRAG_BASE_DIR=/Users/username/Desktop/Your-Project-Folder/data/lightrag
SQLITE_DB_PATH=/Users/username/Desktop/Your-Project-Folder/data/app.db
INGEST_IMAGE_PROCESSOR=gemini      # ocr | gemini
INGEST_DOCUMENT_PROCESSOR=gemini   # unstructured | gemini | openai
INGEST_AUDIO_ASR=whisper          # whisper | openai | gemini
INGESTION_REDACT_PII=false        # true to enable regex-based redaction

# Whisper / ASR configuration
WHISPER_TMP=/tmp
WHISPER_LANG=en
WHISPER_MODEL=large-v3
FASTER_WHISPER_MODEL=medium
FASTER_WHISPER_DEVICE=cpu
FASTER_WHISPER_COMPUTE=int8

# Transformation model (for summarize/QA/flashcards)
TRANSFORM_MODEL_PROVIDER=gemini
TRANSFORM_MODEL=gemini-2.5-flash-lite